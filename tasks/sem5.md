# Семинар 5

**Статья:** [Fathom: Understanding Datacenter Application Network Performance](https://dl.acm.org/doi/pdf/10.1145/3603269.3604815) (SIGCOMM 2023)

## Мини задание (Задание 2)

Google столкнулся с проблемой: невозможно определить кто виноват в том, что RPC-сервис тормозит? Клиент? Сеть? Или разработчики, которые отвечают за сервис? По времени исполнения нельзя было понять, сколько времени обрабатывался запрос, сколько он шел по сети и сколько его "подготавливал/принимал" клиент. Fathom пытается решить эту проблему. Чтобы услуги Fathom не оказались "медвежьими" в масштабах инфраструктуры Google, он должен быть: низкопотребляемым - оверхед всего 0.4% CPU; подробным: собирать детальные метрики с Linux, TCP-стека и RPC; понятным для разработчиков и админов; масштабируемым - уметь обрабатывать миллиарды TCP соединений 24/7.
Решение использует допущение в виде семплирования (берут небольшую выборку из всех запросов), это в целом нормальная практика и дает верное представление о всей системе. Также авторы говорят, что для понимания реальной производительности стоит смотреть на девятки перцентилей, а не всю статистику. Также метрики кластеризуются с помощью GMM, теряя точечность. Отсюда следуют главные компромиссы в решении:
- Семплирование => Получаем большую производительность за счет меньшей детализации
- Агрегация => Уменьшаем стоимость храниения данных за счет уменьшения объема и детализации с помощью t-digest. Теряем инфу об отдельных вызовах, но сохраняем распределение, что полезно для аналитики
- Автоматизация сборки => система не является 100% решением, а лишь предоставляет быстрые подсказки для решение проблем